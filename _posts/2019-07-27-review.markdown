---
layout: post
title:  "Review on Suggestive Annotation: A Deep Active Learning Framework for Biomedical Image Segmentation"
date:   2019-07-26 12:10:09 +0800
categories: deeplearning
---

> Yang, Lin, et al. 
    "Suggestive annotation: A deep active learning framework for biomedical image segmentation." International conference on medical image computing and computer-assisted intervention. Springer, Cham, 2017.

Active learning allows the learning model to choose the training data. 
A well designed active learning model reduces the total number of annotations need to train the model.
The author proposed a new Active Learning framework in this paper.

Two major challenges need to be addressed in this active learning scenario:
* Training speed of the backbone network.
* How to exploit the information provided by the network, p.s. uncertainty, similarity estimation.

# A New Fully Convolutional Network
![new FCN in this work](/asserts/img/20170727_review_1.PNG "New FCN in this work")

An ensemble of techniques to improve generality:
* batch normalization
* residual networks
* bottleneck



# Active learning
Generally speaking, we want to annotate new samples that are:
* hard to learn, that is, the sample has high uncertainty
* representative, that is, the sample are rare and not similar to most annotated data.

## Uncertainty Estimation
Bootstrap is used in this work to estimate uncertainty.
1. train networks with different subsets of training data,
2. forward data to different networks, calculate the variance if predictions.
3. overall uncertainty of each training sample is the mean uncertainty of pixels

While there are some problems:
* when the trained FCNs are updated? each annotation?
* how to update the trained FCN when new annotations are available? (fine-tune? train from scratch?)
* the updating time matters in this scenario

## Similarity Estimation
The features are generated by taking the channel-wise mean of last Conv layer.
Similarity of two images are given by:

$$ sim(I_i, I_j) = cosine\_similarity(I^c_i, I^c_j)$$

Channel-wise means is used to eliminate shifting and rotation variances of images.

## Annotation Suggestion
The problem hers is to define a score for each sample such that the samples with properties we want to get high scores and others get low scores.
Here we want samples that the FCNs make uncertain predicts. 
But some common issues can cause high uncertainty, 
which means many similar samples will be selected for annotation if we only select samples with high uncertainty.
To address this issue, we have to take similarity into account.

For each annotation suggestion stage, First, select top $K$ uncertain images from unannotated dataset $S_u$. 
Then select $k (K > k)$ most representative samples from the top $K$ uncertain samples. 
The $k$ representative samples must increase the coverage of annotated set $S_a$. 
Based on this idea, the author defined the representative score:

$$F(S_a, S_u) = \sum_{I_j\in S_u}f(S_a, I_j)$$

where

$$ f(S_a, I_x) = \max_{I_i\in S_a}sim(I_i, I_x) $$


In this defination, $ f(S_a, I_x) $ score is high if the sample $I_x$ is similar to any sample in $S_a$.
Then we consider what will happen by adding a sample $I_x$ to $S_a$.

\begin{align} 
F(S_a\cup\{I_x\}, S_u-\{I_x\}) & = \sum_{I_j\in S_u}\max(f(S_a, I_j), sim(I_x, I_j) ) - \max(f(S_a, I_j), sim(I_x, I_x) )
\\\\ & =\sum_{I_j\in S_u}\max(f(S_a, I_j), sim(I_x, I_j) ) - 1
\\\\ & = F(S_a, S_u) + \sum_{I_y \in S_u, sim(I_x, I_y) > f(S_a, I_y)}(sim(I_x, i_y)-f(S_a, I_y))) - 1
\end{align}

* if there are samples similar to $I_x$ in both $S_a$ and $S_u$ : 
  adding $I_x$ to $S_a$ will not change $F(S_a, S_u)$ much. 
  Since there exist samples $I_a \in S_a$, $I_b\in S_u$ such that $sim(I_a, I_x)$ and $sim(I_b, I_x)$ is high, So $sim(I_a, I_b)$ is high.
* if there are no samples similar to $I_x$ in $S_a$, adding $I_x$ will significantly increase the score.

So this algorithm tries to find a minimum set of samples that can represent maximum samples in unannotated set.
